<!doctype html>
<html>
<head>
<title>imgplay2-</title>
<link rel="stylesheet" href="//code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">
<script src="//code.jquery.com/jquery-1.11.3.min.js"></script>
<script src="//code.jquery.com/ui/1.11.4/jquery-ui.min.js"></script>
<script>
/**
 * Provides requestAnimationFrame in a cross browser way.
 * http://paulirish.com/2011/requestanimationframe-for-smart-animating/
 */
if ( !window.requestAnimationFrame ) {
	window.requestAnimationFrame = (function() {
		return window.webkitRequestAnimationFrame ||
		window.mozRequestAnimationFrame ||
		window.oRequestAnimationFrame ||
		window.msRequestAnimationFrame ||
		function( /* function FrameRequestCallback */ callback, /* DOMElement Element */ element ) {
			window.setTimeout( callback, 1000 / 60 );
		};
	})();
}
</script>
<style>
	#videoImageContainer {
		/*position: relative;
		overflow: hidden;
		height: 480px;
		width: 640px;
		background-color: green;*/
	}
	.ui-icon { /*float: right;*/ display: inline-block; cursor: pointer; /*margin-bottom: -3px;*/ vertical-align: middle; }
</style>
</head>
<body onload="registerAppletStateHandler()">
<object id="img-applet-ie"
  classid="clsid:8AD9C840-044E-11D1-B3E9-00805F499D93"
  width="100" height="40" style="position:absolute;left:-1000px;top:-1000px;">
  <param name="archive" value="img-applet.jar">
  <param name="code" value="img_applet.ImgApplet">
  <param name="java_status_events" value="true">
  <param name="debug" value="yes">
  <comment>
    <embed id="img-applet"
      type="application/x-java-applet"
      width="100" height="40" style="position:absolute;left:-1000px;top:-1000px;" 
      archive="img-applet.jar"
      code="img_applet.ImgApplet"
      pluginspage="http://java.com/download/"
      java_status_events="true"
      debug="yes" />
  </comment>
</object>
<img id="image0" style="visibility: hidden; display: none;" />
<img id="image1" style="visibility: hidden; display: none;" />
<div id="deviceContainer"></div>
Video: <input id="capture_video" type="checkbox" onclick="checkboxClick(this)" /><label for="capture_video">capture</label> <input id="playback_video" type="checkbox" onclick="checkboxClick(this)" /><label for="playback_video">playback</label>
<br />
Audio: <input id="capture_audio" type="checkbox" onclick="checkboxClick(this)" /><label for="capture_audio">capture</label> <input id="playback_audio" type="checkbox" onclick="checkboxClick(this)" /><label for="playback_audio">playback</label>
<br />
<div id="videoImageContainer"><canvas id="videoImage"></canvas></div>
<!--<input id="list_devices" type="checkbox" onclick="checkboxClick(this)" /><label for="list_devices">list devices</label>
<span style="white-space:pre;" id="list-devices"></span>
<br />
<input id="list_options" type="checkbox" onclick="checkboxClick(this)" /><label for="list_options">list options</label>
<span style="white-space:pre;" id="list-options"></span>-->
<script>

// global variables
var image, videoImage, videoImageContext, applet, applet_ie, _applet, sn = 0, last_img = -1, ffmpeg_ids = {};
// assign variables to HTML elements
image = [ document.getElementById( 'image0' ), document.getElementById( 'image1' ) ];
videoImage = document.getElementById( 'videoImage' );
applet = document.getElementById( 'img-applet' );
applet_ie = document.getElementById( 'img-applet-ie' );
// create '2d' context; background color if no video present
videoImageContext = videoImage.getContext( '2d' );
videoImageContext.fillStyle = '#005337';
videoImageContext.fillRect( 0, 0, videoImage.width, videoImage.height );				
// assign image elements onload handler
var setDimensions = true, curImageIndex;
image[0].onload = image[1].onload = function() {
	if (setDimensions) {
		setDimensions = false;
		$("#videoImageContainer").resizable({
			aspectRatio: this.width / this.height,
			resize: function(event, ui) {
				image[0].width = image[1].width = videoImage.width = ui.size.width;
				image[0].height = image[1].height = videoImage.height = ui.size.height;
				videoImageContext.drawImage( image[curImageIndex], 0, 0, videoImage.width, videoImage.height );
			}
		});
		videoImage.width = this.width;
		videoImage.height = this.height;
		var $videoImageContainer = $('#videoImageContainer');
		$videoImageContainer.width(this.width);
		$videoImageContainer.height(this.height);
	}
	curImageIndex = this === image[0] ? 0 : 1;
	videoImageContext.drawImage( this, 0, 0, videoImage.width, videoImage.height );
};

function checkboxClick(checkbox) {
	_applet[checkbox.checked?'play':'stopPlayback'](ffmpeg_ids[checkbox.id]);
}
function findByFFmpegId(ffmpeg_id) {
	for (var key in ffmpeg_ids)
		if (ffmpeg_ids[key] === ffmpeg_id)
			return key;
}
function checkboxCallback(ffmpeg_id, playing) {
	var key = findByFFmpegId(ffmpeg_id);
	if (key)
		document.getElementById(key).checked = playing;
}

function checkAppletMethod(applet_, method) { return applet_ && (!method || (applet_[method] || typeof(applet_[method]) === "unknown")); }

function checkApplet(method) { if (!_applet) { if (applet && applet.createFFmpeg) { _applet = applet; } else if (applet_ie && typeof(applet_ie.createFFmpeg) === "unknown") { _applet = applet_ie; } } return checkAppletMethod(_applet, method); }

function registerAppletStateHandler() {
	var READY = 2;
	// register onLoad handler if applet has not loaded yet
	if (checkApplet()) {
		if (_applet.status < READY)  {
			_applet.onload = onLoadHandler;
		} else if (_applet.status >= READY) {
			// applet has already loaded or there was an error
			onLoadHandler();
		}
	}
}

function recreateFFmpeg(key, callback, param_arr) {
	if (ffmpeg_ids[key])
		_applet.removeFFmpegById(ffmpeg_ids[key]);
	ffmpeg_ids[key] = _applet.createFFmpegId(callback, param_arr);
}

function renewFFmpeg(key, p1, p2) {
	switch (key) {

	case "capture_video": recreateFFmpeg( key, 'checkboxCallback', [
			'ffmpeg-r', '25',
			'ffmpeg-f:i', 'dshow',
			'ffmpeg-i', 'video=' + p1,		// video device, e.g. "Logitech QuickCam E3500"
			'ffmpeg-c:v', 'libx264',
			'ffmpeg-preset', 'ultrafast',
			'ffmpeg-tune', 'zerolatency',
			'ffmpeg-pix_fmt', 'yuv420p',
			'ffmpeg-g', '50',
			'ffmpeg-an', '',
			'ffmpeg-f:o', 'flv',
			'ffmpeg-o', p2,			// rtmp url, e.g. "rtmp://10.44.43.244/rtmp/v"
			//'debug', 'yes',
		] ); break;

	case "playback_video": recreateFFmpeg( key, 'checkboxCallback', [
			//"ffmpeg-re", "",
			//"ffmpeg-f:i", "",
			"ffmpeg-i", p1,			// rtmp url, e.g. "rtmp://10.44.43.244/rtmp/v",
			//"ffmpeg-i", "rtmp://europaplus.cdnvideo.ru:1935/europaplus-live/eptv_main.sdp",
			//"ffmpeg-i", "rtmp://85.132.78.6:1935/live/muztv.stream",
			//"ffmpeg-i", "http://83.139.104.101/Content/HLS/Live/Channel(Sk_1)/index.m3u8",
			//"ffmpeg-map", "0:6",
			"ffmpeg-c:v", "mjpeg",
			"ffmpeg-q:v", "0.0",
 /* ‘-vsync parameter’
    Video sync method. For compatibility reasons old values can be specified as numbers. 
    Newly added values will have to be specified as strings always.
    ‘0, passthrough’ - Each frame is passed with its timestamp from the demuxer to the muxer. 
    ‘1, cfr’ - Frames will be duplicated and dropped to achieve exactly the requested constant frame rate. 
    ‘2, vfr’ - Frames are passed through with their timestamp or dropped so as to prevent 2 frames from having the same timestamp. 
    ‘drop’ - As passthrough but destroys all timestamps, making the muxer generate fresh timestamps based on frame-rate. 
    ‘-1, auto’ - Chooses between 1 and 2 depending on muxer capabilities. This is the default method.
  */
			"ffmpeg-vsync", "0",
			"ffmpeg-f:o", "mjpeg",
			"ffmpeg-an", "",
			//"ffmpeg-muxpreload", "10",
			//"ffmpeg-muxdelay", "10",
			//"ffmpeg-loglevel", "warning",
			"drop-unused-frames", "yes",
			"debug", "yes",
		] ); break;

	case "capture_audio": recreateFFmpeg( key, 'checkboxCallback', [
			'ffmpeg-f:i', 'dshow',
			'ffmpeg-audio_buffer_size', '50',
			'ffmpeg-i', 'audio=' + p1,		// audio device, e.g. "Microphone (USB Audio Device)"
			'ffmpeg-c:a', 'libmp3lame',
			'ffmpeg-async', '1',
			'ffmpeg-vn', '',
			'ffmpeg-f:o', 'flv',
			'ffmpeg-o', p2,			// rtmp url, e.g. "rtmp://10.44.43.244/rtmp/a"
			//'debug', 'yes',
		] ); break;

	case "playback_audio": recreateFFmpeg( key, 'checkboxCallback', [
			"ffmpeg-re", "no",
			"ffmpeg-analyzeduration", "1000",
			"ffmpeg-rtmp_buffer", "0",
			"ffmpeg-rtmp_live", "live",
			//"ffmpeg-f:i", "",
			"ffmpeg-i", p1,			// rtmp url, e.g. "rtmp://10.44.43.244/rtmp/a"
			//"ffmpeg-c:a", "libmp3lame",
			//"ffmpeg-f:o", "mp3",
			//"mp3-frames-per-chunk", "1",
			"ffmpeg-f:o", "wav",
			"ffmpeg-vn", "",
			//"debug", "yes",
		] ); break;
	}
}

function callFFmpeg(key, p1) {
	var _ffmpeg_id, defer = $.Deferred().always(function () {
		if (_ffmpeg_id) {
			_applet.removeFFmpegById(_ffmpeg_id);
			//alert("remove: " + _ffmpeg_id);
		}
	});
	window.dataCallback = function (ffmpeg_id, playing) {
		if (!playing) {
			defer.resolve(_applet.getStderrData(ffmpeg_id));
			//alert("resolve: " + ffmpeg_id);
		}
	};
	switch (key) {

	case "list_devices": _ffmpeg_id = _applet.createFFmpegId( 'dataCallback', [
			'ffmpeg-list_devices', 'true',
			'ffmpeg-f:i', 'dshow',
			'ffmpeg-i', 'dummy',
			'ffmpeg-o', '',
			'debug', 'yes',
		] ); break;

	case "list_options": _ffmpeg_id = _applet.createFFmpegId( 'dataCallback', [
			'ffmpeg-list_options', 'true',
			'ffmpeg-f:i', 'dshow',
			'ffmpeg-i', p1,			// device, e.g. 'video=Logitech QuickCam Communicate STX', or 'audio=Logitech Mic (Communicate STX)'
			'ffmpeg-o', '',
			'debug', 'yes',
		] ); break;
	}
	if (_ffmpeg_id) {
		_applet.play(_ffmpeg_id);
	}
	return defer.promise();
}

function onLoadHandler() {
	// event handler for ready state
	var listDevices = function () {
		$("#deviceContainer")/*.addClass("ui-state-default")*/.empty();
		callFFmpeg("list_devices").then(function (res) {
			var re = /\[\s*dshow\s*@\s*[a-fA-F0-9]+\s*\]\s*"?(.*?)"?\s*\r?\n/ig;
			var tmp, arr = []; // , out = "";
			while ((tmp = re.exec(res)) !== null) {
				//out += "\r\n" + tmp[1];
				arr.push(tmp[1]);
			}
			//document.getElementById("list-devices").innerHTML = out;
			re = /^\s*Direct\s*Show\s*(video|audio)\s*devices\s*$/i;
			var $select;
			for (var i in arr) {
				if (re.test(arr[i])) {
					$select = $("<select></select>").appendTo("#deviceContainer");
					$("<option></option>").attr({ "value": arr[i], "disabled": "disabled" }).text(arr[i]).appendTo($select);
				} else {
					$("<option></option>").attr("value", arr[i]).text(arr[i]).appendTo($select);
				}
			}
			$("<span class='ui-icon ui-icon-refresh'></span>").appendTo("#deviceContainer").click(listDevices);
		});
	};
	listDevices();
	renewFFmpeg("capture_video", 'Logitech QuickCam E3500', 'rtmp://10.44.43.244/rtmp/v');
	renewFFmpeg("playback_video", 'rtmp://10.44.43.244/rtmp/v');
	renewFFmpeg("capture_audio", 'Microphone (USB Audio Device)', 'rtmp://10.44.43.244/rtmp/a');
	renewFFmpeg("playback_audio", 'rtmp://10.44.43.244/rtmp/a');
	//renewFFmpeg("list_devices");
	//renewFFmpeg("list_options", 'video=Logitech QuickCam Communicate STX');
}

// start the loop				
animate();

function animate() {
	requestAnimationFrame( animate );
	render();
}

var cnt = 0;

function render() {
	//if ((++cnt) % 2 != 0)
	//	return;
	if (ffmpeg_ids["playback_video"]) {
		var sn_ = _applet.getSN(ffmpeg_ids["playback_video"]);
		if ( sn_ != sn && sn_ > 0 ) {
			sn = sn_;
			var dataURI = _applet.getDataURI(ffmpeg_ids["playback_video"]);
			// drop frames accumulated in the queue
/*
			while (_applet.getSN(ffmpeg_ids["playback_video"]) > sn) {
				console.log("dropped frame # " + sn);
				sn = _applet.getSN(ffmpeg_ids["playback_video"]);
				dataURI = _applet.getDataURI(ffmpeg_ids["playback_video"]);
			}
*/ // we do it in the applet now when drop-unused-frames="yes"
			// assign image src
			image[last_img = (last_img + 1) % 2].src = dataURI;
		}
	}
}
</script>

</body>
</html>
